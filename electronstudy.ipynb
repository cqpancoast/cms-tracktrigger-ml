{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electron Study\n",
    "\n",
    "The aim of this study is to determine whether the introduction of new track properties, namely `chi2rphi` and `chi2rz`, improve the performance of machine learning algorithms dedicated to telling whether electron-labeled track-trigger tracks are real or fake.\n",
    "\n",
    "The Monte-Carlo samples available are a QCD sample, a Z boson to muon-muon sample, and a Z boson to electron-electron sample. Each sample is run for the D49 detector geometry and contains 1000 events, each of which has a pileup of about 200.\n",
    "\n",
    "Much of the code here is run using the `ntupledicts` package, which can be found [here](https://github.com/cqpancoast/ntupledicts), along with a simple tutorial that covers all code used here.\n",
    "The requirements for running this notebook are the same as the ones listed for running `ntupledicts` in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uproot import open as uproot_open\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Softmax\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from ntupledicts import operations as ndops\n",
    "from ntupledicts import analyze as ndanl\n",
    "from ntupledicts.operations import select as sel\n",
    "from ntupledicts.ml import data as ndmldata\n",
    "from ntupledicts.ml import predict as ndmlpred\n",
    "from ntupledicts.ml import models as ndmlmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "\n",
    "Grab tracks from stored ntuples, perform cuts, process into datasets.\n",
    "Take all electron tracks from the primary interaction and an equal number of fake tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the ntuples we want data from\n",
    "input_files = [\"eventsets/ZMM_PU200_D49.root\",\n",
    "    \"eventsets/ZEE_PU200_D49.root\",\n",
    "    \"eventsets/QCD_PU200_D49.root\"]\n",
    "#input_files = [\"eventsets/TTbar_PU200_D49_20.root\"]\n",
    "\n",
    "# Create list of uproot event sets for easy data access\n",
    "event_sets = []\n",
    "for input_file in input_files:\n",
    "    event_sets.append(next(iter(uproot_open(input_file).values()))[\"eventTree\"])\n",
    "    \n",
    "# What track properties do we want available to play with?\n",
    "# We can select which ones we want our models to train on later\n",
    "track_properties = [\"pt\", \"eta\", \"z0\", \"nstub\",\n",
    "                        \"hitpattern\", \"chi2\", \"bendchi2\", \"chi2rphi\", \"chi2rz\"]\n",
    "properties_by_track_type = {\"trk\": track_properties + [\"matchtp_pdgid\", \"genuine\"],\n",
    "                            \"matchtrk\": track_properties, \n",
    "                            \"tp\": [\"pdgid\", \"eventid\"]}\n",
    "\n",
    "# Create ntuple dict from event sets\n",
    "ntuple_dict = ndops.uproot_ntuples_to_ntuple_dict(event_sets, properties_by_track_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Cuts\n",
    "\n",
    "We want electron matchtrks from the primary interaction and an equal number of fake trks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Would we like to consider only a portion of this dataset? (Typically done for speed reasons.)\n",
    "reduce_ntuple_dict = False\n",
    "reduction_size = 1000000  # number of tracks to reduce to\n",
    "if reduce_ntuple_dict:\n",
    "    ntuple_dict = ndops.reduce_ntuple_dict(ntuple_dict, reduction_size)\n",
    "\n",
    "# Get electron matchtrks from the primary interaction, fake trks\n",
    "# Note that cutting on tp's also cuts on matchtrks\n",
    "el_sel = sel([sel(11), sel(-11)])\n",
    "ntuple_dict = ndops.cut_ntuple_dict(ntuple_dict, {\"tp\": {\"pdgid\": el_sel, \"eventid\": sel(0)},\n",
    "                                            \"matchtrk\": {\"hitpattern\": sel([sel(-999)], invert=True)},\n",
    "                                                 \"trk\": {\"genuine\": sel(0)}})\n",
    "matchtrk_els = ntuple_dict[\"matchtrk\"]\n",
    "matchtrk_els[\"genuine\"] = [1 for _ in range(ndops.track_prop_dict_length(matchtrk_els))]\n",
    "    # All matchtrks are genuine\n",
    "trk_not_gens = ntuple_dict[\"trk\"]\n",
    "trk_not_gens = ndops.reduce_track_prop_dict(trk_not_gens, ndops.track_prop_dict_length(matchtrk_els))\n",
    "\n",
    "# Cut down the number of not genuine tracks to the number of electrons\n",
    "print(\"Number of primary interaction electron tracks: {}\".format(ndops.track_prop_dict_length(matchtrk_els)))\n",
    "print(\"Number of not genuine tracks: {}\".format(ndops.track_prop_dict_length(trk_not_gens)))\n",
    "\n",
    "# Now, add them together.\n",
    "# A UserWarning is expected here, as trk_not_gens has a property \"matchtp_pdgid\" that matchtrk_els doesn't have.\n",
    "els_and_fakes_tpd = ndops.shuffle_track_prop_dict(\n",
    "                        ndops.add_track_prop_dicts([matchtrk_els, trk_not_gens]),\n",
    "                        seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Stub-Based Track Properties\n",
    "\n",
    "Use hitpattern and eta to determine how many missing 2S and PS stubs there are for each track. (Note that this is post-cuts â€” if we want to place cuts on these, we'll move this cell before the cut application cell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count layers meeting these conditions for each track. (see ntupledicts.analyze for documentation)\n",
    "missing_2S_layer = lambda expected, hit, ps: not ps and expected and not hit\n",
    "missing_PS_layer = lambda expected, hit, ps: ps and expected and not hit\n",
    "\n",
    "els_and_fakes_tpd[\"missing2S\"] = ndanl.create_stub_info_list(els_and_fakes_tpd,\n",
    "        ndanl.basic_process_stub_info(missing_2S_layer))\n",
    "els_and_fakes_tpd[\"missingPS\"] = ndanl.create_stub_info_list(els_and_fakes_tpd,\n",
    "        ndanl.basic_process_stub_info(missing_PS_layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process into Datasets\n",
    "\n",
    "Process the ntuple dict above into `TrackPropertiesDataset`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_track_props = [\"pt\", \"eta\", \"z0\", \"bendchi2\", \"nstub\", \"missing2S\", \"missingPS\"]  \n",
    "    # Track properties that both sets of models will use.\n",
    "non_sc2_data_props = common_track_props + [\"chi2\"]  # Our first set of models will also include chi2.\n",
    "label_property = \"genuine\"  # What property are we trying to predict?\n",
    "split_list = [.7, .2, .1]   # How many datasets should we create, and with what relative sizes?\n",
    "train_ds, eval_ds, test_ds = ndmldata.TrackPropertiesDataset(els_and_fakes_tpd,\n",
    "                                                             label_property,\n",
    "                                                             non_sc2_data_props).split(split_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Models\n",
    "\n",
    "Build two neural networks and two gradient boosted decision trees, train one of them on data containing the split chi2 variables and one of them on data without them. Also define two sets of predictive cuts to compare our models against."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make our non-split chi2 set of models\n",
    "NN = ndmlmodels.make_neuralnet(train_ds, eval_dataset=eval_ds, hidden_layers=[15, 8], epochs=10)\n",
    "GBDT = ndmlmodels.make_gbdt(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Chi2 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove chi2 and introduce the split chi2's as active data properties\n",
    "sc2_data_props = common_track_props + [\"chi2rphi\", \"chi2rz\"]\n",
    "for ds in [train_ds, eval_ds, test_ds]:\n",
    "    ds.set_active_data_properties(sc2_data_props)\n",
    "\n",
    "# Make our split chi2 set of models (sc2 stands for split chi2)\n",
    "NN_sc2 = ndmlmodels.make_neuralnet(train_ds, eval_dataset=eval_ds, hidden_layers=[15, 8], epochs=10)\n",
    "GBDT_sc2 = ndmlmodels.make_gbdt(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictive cuts\n",
    "chi2_cuts = {\"chi2\": sel(0, 70), \"bendchi2\": sel(0, 2.5)}\n",
    "sc2_cuts = {\"chi2rz\": sel(0, 5), \"bendchi2\": sel(0, 2.5)}  # Chi2rz cuts perform much better for electrons than chi2rphi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Predictions\n",
    "\n",
    "Use the test dataset `test_ds` that hasn't been used for training to make predicted labels. These will be probablistic in the case of the models `NN` and `GBDT` and exact in the case of `cuts`. Store these predictions in `test_ds` for easy future access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add normal chi2 predictions\n",
    "test_ds.add_prediction(\"NN\", ndmlpred.predict_labels(NN, test_ds.get_data(non_sc2_data_props)))\n",
    "test_ds.add_prediction(\"GBDT\", ndmlpred.predict_labels(GBDT, test_ds.get_data(non_sc2_data_props)))\n",
    "test_ds.add_prediction(\"chi2_cuts\", ndmlpred.predict_labels_cuts(chi2_cuts, test_ds))\n",
    "\n",
    "# Add split chi2 predictions\n",
    "test_ds.add_prediction(\"NN_sc2\", ndmlpred.predict_labels(NN_sc2, test_ds.get_data(sc2_data_props)))\n",
    "test_ds.add_prediction(\"GBDT_sc2\", ndmlpred.predict_labels(GBDT_sc2, test_ds.get_data(sc2_data_props)))\n",
    "test_ds.add_prediction(\"sc2_cuts\", ndmlpred.predict_labels_cuts(sc2_cuts, test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Model Predictions\n",
    "\n",
    "Now we'll compare the two sets of predictions to see which ones perform better. These plots will measure the true positive rate and false positive rate (TPR and FPR) of these predictions with respect to various threshold values and track properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ntupledicts import plot as ndplot\n",
    "from ntupledicts.ml import plot as ndmlplot\n",
    "from matplotlib.pyplot import cla, sca, gca, show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(These import statementa are down here for debug purposes - so we don't have to rerun all the cells to change something in `ml.plot` suite or add some new `matplotlib` import.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "Plot the models' paths through TPR/FPR space as the threshold on probablistically predicted labels changes. Also includes the cuts' point in that space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlims=(0, 1)\n",
    "ylims=(0, 1)\n",
    "\n",
    "ndmlplot.plot_rocs(test_ds, [\"NN\", \"GBDT\"], [\"chi2_cuts\"], xlims=xlims, ylims=ylims)\n",
    "ndmlplot.plot_rocs(test_ds, [\"NN_sc2\", \"GBDT_sc2\"], [\"sc2_cuts\"], xlims=xlims, ylims=ylims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle TPR and FPR by Threshold\n",
    "\n",
    "Plot TPR and FPR for particles of a particular type as the threshold for assigning probablistic values to either genuine or not genuine shifts from zero to one. Make plots for both sets of models to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TPR/FPR vs decision thresh * models, ov. particle type\n",
    "for pred_comparison, pred_comp_name in zip(\n",
    "        [ndmlpred.true_positive_rate, ndmlpred.false_positive_rate],\n",
    "        [\"TPR\", \"FPR\"]):\n",
    "    ax = gca()\n",
    "    for pred_name in test_ds.get_all_prediction_names():\n",
    "        if \"cut\" in pred_name:\n",
    "            continue\n",
    "        ax = ndmlplot.plot_pred_comparison_by_threshold(test_ds,\n",
    "                pred_name, pred_comparison, legend_id=pred_name, ax=ax)\n",
    "    ax.set_ylabel(pred_comp_name)\n",
    "    ax.set_title(\"{} of model predictions by threshold\".format(pred_comp_name))\n",
    "    ax.legend()\n",
    "    show()\n",
    "    cla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle TPR and FPR by Track Property\n",
    "\n",
    "Plot TPR and FPR for particles of a particular type for binned values of some track property. The aim of this is to get a sense of how model performance depends upon track properties like pT and eta. Make plots for both sets of models to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPR/FPR vs some track prop * models, ov. particle type.\n",
    "# Parametrized by binning property.\n",
    "\n",
    "# A dictionary from track properties to bin specifiers\n",
    "binning_dict = {\"pt\": (2, 100, 30)}\n",
    "\n",
    "for binning_prop, bins in zip(binning_dict.keys(), binning_dict.values()):\n",
    "    for pred_comparison, pred_comp_name in zip(\n",
    "            [ndmlpred.true_positive_rate, ndmlpred.false_positive_rate],\n",
    "            [\"TPR\", \"FPR\"]):\n",
    "        ax = gca()\n",
    "        for pred_name in test_ds.get_all_prediction_names():\n",
    "            ax = ndmlplot.plot_pred_comparison_by_track_property(\n",
    "                    test_ds, pred_name,\n",
    "                    pred_comparison, binning_prop, bins=bins,\n",
    "                    legend_id=pred_name, ax=ax)\n",
    "        ax.set_ylabel(pred_comp_name)\n",
    "        ax.set_title(\"{} of model predictions vs. {}\".format(pred_comp_name, binning_prop))\n",
    "        ax.legend()\n",
    "        show()\n",
    "        cla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "Bacon ipsum dolor amet..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
